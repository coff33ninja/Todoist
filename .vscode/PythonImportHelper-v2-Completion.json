[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "datasets",
        "description": "datasets",
        "isExtraImport": true,
        "detail": "datasets",
        "documentation": {}
    },
    {
        "label": "DistilBertTokenizerFast",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "AutoModelForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "Trainer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TrainingArguments",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "DistilBertTokenizerFast",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "spacy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "spacy",
        "description": "spacy",
        "detail": "spacy",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "softmax",
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "isExtraImport": true,
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "pytesseract",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytesseract",
        "description": "pytesseract",
        "detail": "pytesseract",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "DataPreprocessor",
        "importPath": "ai.data_preprocessing",
        "description": "ai.data_preprocessing",
        "isExtraImport": true,
        "detail": "ai.data_preprocessing",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "jsonify",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "send_from_directory",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "CORS",
        "importPath": "flask_cors",
        "description": "flask_cors",
        "isExtraImport": true,
        "detail": "flask_cors",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "NLUProcessor",
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "isExtraImport": true,
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "NLUProcessor",
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "isExtraImport": true,
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "NLUProcessor",
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "isExtraImport": true,
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "NLUProcessor",
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "isExtraImport": true,
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "ReceiptProcessor",
        "importPath": "ai.ocr_processor",
        "description": "ai.ocr_processor",
        "isExtraImport": true,
        "detail": "ai.ocr_processor",
        "documentation": {}
    },
    {
        "label": "ReceiptProcessor",
        "importPath": "ai.ocr_processor",
        "description": "ai.ocr_processor",
        "isExtraImport": true,
        "detail": "ai.ocr_processor",
        "documentation": {}
    },
    {
        "label": "threading",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "threading",
        "description": "threading",
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "InventoryManager",
        "importPath": "core.inventory_manager",
        "description": "core.inventory_manager",
        "isExtraImport": true,
        "detail": "core.inventory_manager",
        "documentation": {}
    },
    {
        "label": "InventoryManager",
        "importPath": "core.inventory_manager",
        "description": "core.inventory_manager",
        "isExtraImport": true,
        "detail": "core.inventory_manager",
        "documentation": {}
    },
    {
        "label": "InventoryManager",
        "importPath": "core.inventory_manager",
        "description": "core.inventory_manager",
        "isExtraImport": true,
        "detail": "core.inventory_manager",
        "documentation": {}
    },
    {
        "label": "ReceiptProcessor",
        "importPath": "ai.receipt_processor",
        "description": "ai.receipt_processor",
        "isExtraImport": true,
        "detail": "ai.receipt_processor",
        "documentation": {}
    },
    {
        "label": "TaskManager",
        "importPath": "core.task_manager",
        "description": "core.task_manager",
        "isExtraImport": true,
        "detail": "core.task_manager",
        "documentation": {}
    },
    {
        "label": "BudgetTracker",
        "importPath": "utils.budget_tracker",
        "description": "utils.budget_tracker",
        "isExtraImport": true,
        "detail": "utils.budget_tracker",
        "documentation": {}
    },
    {
        "label": "logging.handlers",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging.handlers",
        "description": "logging.handlers",
        "detail": "logging.handlers",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "FlaskClient",
        "importPath": "flask.testing",
        "description": "flask.testing",
        "isExtraImport": true,
        "detail": "flask.testing",
        "documentation": {}
    },
    {
        "label": "app",
        "importPath": "core.main",
        "description": "core.main",
        "isExtraImport": true,
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "DataPreprocessor",
        "kind": 6,
        "importPath": "ai.data_preprocessing",
        "description": "ai.data_preprocessing",
        "peekOfCode": "class DataPreprocessor:\n    \"\"\"\n    A class for data preprocessing and feature engineering.\n    \"\"\"\n    def __init__(self):\n        pass\n    def preprocess_text(self, text):\n        \"\"\"\n        Preprocesses the input text data.\n        :param text: The text data to preprocess.",
        "detail": "ai.data_preprocessing",
        "documentation": {}
    },
    {
        "label": "NLUModel",
        "kind": 6,
        "importPath": "ai.nlu_model",
        "description": "ai.nlu_model",
        "peekOfCode": "class NLUModel:\n    def __init__(\n        self,\n        model_name=\"distilbert-base-uncased\",\n        model_save_path=\"ai_models/nlu_model\",\n    ):\n        self.model_name = model_name\n        self.model_save_path = model_save_path\n        self.tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n        self.model = DistilBertForSequenceClassification.from_pretrained(model_name)",
        "detail": "ai.nlu_model",
        "documentation": {}
    },
    {
        "label": "ModelError",
        "kind": 6,
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "peekOfCode": "class ModelError(Exception):\n    \"\"\"Custom exception for model loading errors.\"\"\"\n    pass\nclass NLUProcessor:\n    def __init__(self, model_path=\"ai_models/nlu_model\", db_path=\"inventory.db\", max_retries=3, retry_delay=1):\n        \"\"\"Initialize the NLUProcessor with model and database connections.\n        Args:\n            model_path: Path to the NLU model\n            db_path: Path to the SQLite database\n            max_retries: Maximum number of retries for operations",
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "NLUProcessor",
        "kind": 6,
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "peekOfCode": "class NLUProcessor:\n    def __init__(self, model_path=\"ai_models/nlu_model\", db_path=\"inventory.db\", max_retries=3, retry_delay=1):\n        \"\"\"Initialize the NLUProcessor with model and database connections.\n        Args:\n            model_path: Path to the NLU model\n            db_path: Path to the SQLite database\n            max_retries: Maximum number of retries for operations\n            retry_delay: Delay between retries in seconds\n        \"\"\"\n        self.max_retries = max_retries",
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "ai.nlu_processor",
        "description": "ai.nlu_processor",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass ModelError(Exception):\n    \"\"\"Custom exception for model loading errors.\"\"\"\n    pass\nclass NLUProcessor:\n    def __init__(self, model_path=\"ai_models/nlu_model\", db_path=\"inventory.db\", max_retries=3, retry_delay=1):\n        \"\"\"Initialize the NLUProcessor with model and database connections.\n        Args:\n            model_path: Path to the NLU model\n            db_path: Path to the SQLite database",
        "detail": "ai.nlu_processor",
        "documentation": {}
    },
    {
        "label": "ReceiptProcessor",
        "kind": 6,
        "importPath": "ai.ocr_processor",
        "description": "ai.ocr_processor",
        "peekOfCode": "class ReceiptProcessor:\n    def __init__(self):\n        pass\n    def preprocess_image(self, image_path):\n        \"\"\"Preprocess the receipt image for better OCR results\"\"\"\n        try:\n            # Load image\n            img = cv2.imread(image_path)\n            # Convert to grayscale\n            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)",
        "detail": "ai.ocr_processor",
        "documentation": {}
    },
    {
        "label": "ReceiptProcessor",
        "kind": 6,
        "importPath": "ai.receipt_processor",
        "description": "ai.receipt_processor",
        "peekOfCode": "class ReceiptProcessor:\n    def __init__(self, tesseract_path=None):\n        if tesseract_path:\n            pytesseract.pytesseract.tesseract_cmd = tesseract_path\n    def preprocess_image(self, image_path):\n        data_preprocessor = DataPreprocessor()\n        \"\"\"Preprocess image for better OCR results\"\"\"\n        img = cv2.imread(image_path)\n        gray = data_preprocessor.preprocess_image(img)\n        # Apply thresholding",
        "detail": "ai.receipt_processor",
        "documentation": {}
    },
    {
        "label": "get_db",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_db():\n    \"\"\"Get database connection with row factory.\"\"\"\n    db_path = os.path.join(db_dir, 'inventory.db')\n    try:\n        conn = sqlite3.connect(db_path)\n    except Exception as e:\n        print(f\"Database connection error: {e}\")\n        return None\n    conn.row_factory = sqlite3.Row\n    return conn",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "process_query",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def process_query():\n    \"\"\"Process natural language queries.\"\"\"\n    try:\n        data = request.get_json()\n        if not data or \"query\" not in data:\n            return jsonify({\"error\": \"Missing query in request\"}), 400\n        query = data[\"query\"]\n        result = nlu_processor.process_natural_language_query(query, get_db)\n        if \"error\" in result:\n            logging.error(\"Error in NLU processing: %s\", result[\"error\"])",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_categories",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_categories():\n    \"\"\"Get list of predefined categories.\"\"\"\n    try:\n        conn = get_db()\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT name FROM categories ORDER BY name\")\n        categories = [row[0] for row in cursor.fetchall()]\n        conn.close()\n        return jsonify({\"categories\": categories})\n    except Exception as e:",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "add_item",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def add_item():\n    \"\"\"Add a new item to the inventory.\"\"\"\n    try:\n        data = request.get_json()\n        required_fields = [\"name\", \"quantity\", \"price\", \"location\"]\n        # Validate required fields\n        if not all(field in data for field in required_fields):\n            return (\n                jsonify(\n                    {",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "delete_item",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def delete_item(item_id):\n    \"\"\"Delete an item from the inventory.\"\"\"\n    try:\n        conn = get_db()\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT 1 FROM items WHERE id = ?\", (item_id,))\n        if not cursor.fetchone():\n            return jsonify({\"error\": \"Item not found\"}), 404\n        cursor.execute(\"DELETE FROM items WHERE id = ?\", (item_id,))\n        conn.commit()",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "get_locations",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def get_locations():\n    \"\"\"Get list of existing locations for autocomplete.\"\"\"\n    try:\n        conn = get_db()\n        cursor = conn.cursor()\n        cursor.execute('SELECT DISTINCT location FROM items WHERE location IS NOT NULL')\n        locations = [row[0] for row in cursor.fetchall()]\n        conn.close()\n        return jsonify({\"locations\": locations})\n    except Exception as e:",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "health_check",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def health_check():\n    \"\"\"Health check endpoint.\"\"\"\n    return jsonify({\"status\": \"healthy\"})\n@app.route('/api/upload_receipt', methods=['POST'])\ndef upload_receipt():\n    try:\n        print(\"Received upload_receipt request\")\n        if 'file' not in request.files:\n            print(\"No file part in request\")\n            return jsonify({\"error\": \"No file part\"}), 400",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "upload_receipt",
        "kind": 2,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "def upload_receipt():\n    try:\n        print(\"Received upload_receipt request\")\n        if 'file' not in request.files:\n            print(\"No file part in request\")\n            return jsonify({\"error\": \"No file part\"}), 400\n        file = request.files['file']\n        if file.filename == '':\n            print(\"No selected file\")\n            return jsonify({\"error\": \"No selected file\"}), 400",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "app = Flask(__name__)\nCORS(app)  # Enable CORS for all routes\n# Initialize NLU processor\nnlu_processor = NLUProcessor(model_path=\"ai_models/nlu_model.pkl\")\n# Ensure the uploads directory exists\nuploads_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'uploads')\nos.makedirs(uploads_dir, exist_ok=True)\n# Ensure the db directory exists\ndb_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'db')\nos.makedirs(db_dir, exist_ok=True)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "nlu_processor",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "nlu_processor = NLUProcessor(model_path=\"ai_models/nlu_model.pkl\")\n# Ensure the uploads directory exists\nuploads_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'uploads')\nos.makedirs(uploads_dir, exist_ok=True)\n# Ensure the db directory exists\ndb_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'db')\nos.makedirs(db_dir, exist_ok=True)\ndef get_db():\n    \"\"\"Get database connection with row factory.\"\"\"\n    db_path = os.path.join(db_dir, 'inventory.db')",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "uploads_dir",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "uploads_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'uploads')\nos.makedirs(uploads_dir, exist_ok=True)\n# Ensure the db directory exists\ndb_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'db')\nos.makedirs(db_dir, exist_ok=True)\ndef get_db():\n    \"\"\"Get database connection with row factory.\"\"\"\n    db_path = os.path.join(db_dir, 'inventory.db')\n    try:\n        conn = sqlite3.connect(db_path)",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "db_dir",
        "kind": 5,
        "importPath": "backend.app",
        "description": "backend.app",
        "peekOfCode": "db_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'db')\nos.makedirs(db_dir, exist_ok=True)\ndef get_db():\n    \"\"\"Get database connection with row factory.\"\"\"\n    db_path = os.path.join(db_dir, 'inventory.db')\n    try:\n        conn = sqlite3.connect(db_path)\n    except Exception as e:\n        print(f\"Database connection error: {e}\")\n        return None",
        "detail": "backend.app",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "backend.init_db",
        "description": "backend.init_db",
        "peekOfCode": "def init_db():\n    # Get the path to the db directory\n    db_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'db')\n    os.makedirs(db_dir, exist_ok=True)\n    db_path = os.path.join(db_dir, 'inventory.db')\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    # Create purchases table\n    cursor.execute('''\n    CREATE TABLE IF NOT EXISTS purchases (",
        "detail": "backend.init_db",
        "documentation": {}
    },
    {
        "label": "InventoryManager",
        "kind": 6,
        "importPath": "core.inventory_manager",
        "description": "core.inventory_manager",
        "peekOfCode": "class InventoryManager:\n    _instance = None\n    _lock = threading.Lock()\n    def __init__(self, db_path='inventory.db'):\n        self.db_path = db_path\n        self._local = threading.local()\n    def get_connection(self):\n        \"\"\"Get a thread-local database connection\"\"\"\n        if not hasattr(self._local, 'conn'):\n            self._local.conn = sqlite3.connect(self.db_path)",
        "detail": "core.inventory_manager",
        "documentation": {}
    },
    {
        "label": "get_db",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def get_db():\n    \"\"\"Get database connection with row factory\"\"\"\n    if not hasattr(db_local, \"conn\"):\n        db_local.conn = sqlite3.connect(DATABASE)\n        db_local.conn.row_factory = sqlite3.Row\n    return db_local.conn\ndef close_db():\n    \"\"\"Close the database connection\"\"\"\n    if hasattr(db_local, \"conn\"):\n        try:",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "close_db",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def close_db():\n    \"\"\"Close the database connection\"\"\"\n    if hasattr(db_local, \"conn\"):\n        try:\n            db_local.conn.close()\n        except Exception:\n            pass\n        finally:\n            if hasattr(db_local, \"conn\"):\n                del db_local.conn",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "teardown_db",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def teardown_db(_):\n    close_db()\ndef init_db():\n    # Close any existing connections\n    close_db()\n    # Initialize components with thread-local storage after database reset\n    global inventory, receipt_processor, task_manager, budget_tracker\n    try:\n        # Initialize the inventory manager first, which will create the tables\n        inventory = InventoryManager(DATABASE)",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def init_db():\n    # Close any existing connections\n    close_db()\n    # Initialize components with thread-local storage after database reset\n    global inventory, receipt_processor, task_manager, budget_tracker\n    try:\n        # Initialize the inventory manager first, which will create the tables\n        inventory = InventoryManager(DATABASE)\n        # Initialize other components\n        receipt_processor = ReceiptProcessor()",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "add_item",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def add_item():\n    data = request.get_json()\n    required_fields = [\"name\"]\n    if not all(field in data for field in required_fields):\n        return jsonify({\"error\": \"Missing required fields\"}), 400\n    try:\n        item_id = inventory.add_item(\n            name=data[\"name\"],\n            description=data.get(\"description\"),\n            quantity=data.get(\"quantity\", 1),",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "add_repair",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def add_repair():\n    data = request.get_json()\n    required_fields = [\"item_id\", \"description\"]\n    if not all(field in data for field in required_fields):\n        return jsonify({\"error\": \"Missing required fields\"}), 400\n    try:\n        # Add the repair record\n        repair_id = task_manager.add_repair(\n            item_id=data[\"item_id\"],\n            description=data[\"description\"],",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "upload_receipt",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def upload_receipt():\n    if \"file\" not in request.files:\n        return jsonify({\"error\": \"No file part\"}), 400\n    file = request.files[\"file\"]\n    if file.filename == \"\":\n        return jsonify({\"error\": \"No selected file\"}), 400\n    try:\n        # Sanitize the filename\n        safe_filename = secure_filename(file.filename)  # Sanitize the filename\n        # Save the file",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "get_receipt",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def get_receipt(filename):\n    return send_from_directory(UPLOAD_FOLDER, filename)\n@app.route(\"/api/query\", methods=[\"POST\"])\ndef handle_query():\n    data = request.get_json()\n    query_text = data.get(\"query\", \"\")\n    if not query_text:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    try:\n        # Import NLUProcessor only when needed to avoid circular imports",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "handle_query",
        "kind": 2,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "def handle_query():\n    data = request.get_json()\n    query_text = data.get(\"query\", \"\")\n    if not query_text:\n        return jsonify({\"error\": \"No query provided\"}), 400\n    try:\n        # Import NLUProcessor only when needed to avoid circular imports\n        from ai.nlu_processor import NLUProcessor\n        nlu_processor = NLUProcessor()\n        result = nlu_processor.process_natural_language_query(",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "logger = logging.getLogger(__name__)\n# Initialize Flask app\napp = Flask(__name__)\nCORS(app)\n# Configure upload folder\nUPLOAD_FOLDER = \"uploads\"\nif not os.path.exists(UPLOAD_FOLDER):\n    os.makedirs(UPLOAD_FOLDER)\n# Database setup\nDATABASE = \"inventory.db\"",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "app = Flask(__name__)\nCORS(app)\n# Configure upload folder\nUPLOAD_FOLDER = \"uploads\"\nif not os.path.exists(UPLOAD_FOLDER):\n    os.makedirs(UPLOAD_FOLDER)\n# Database setup\nDATABASE = \"inventory.db\"\ndb_local = threading.local()\ndef get_db():",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "UPLOAD_FOLDER",
        "kind": 5,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "UPLOAD_FOLDER = \"uploads\"\nif not os.path.exists(UPLOAD_FOLDER):\n    os.makedirs(UPLOAD_FOLDER)\n# Database setup\nDATABASE = \"inventory.db\"\ndb_local = threading.local()\ndef get_db():\n    \"\"\"Get database connection with row factory\"\"\"\n    if not hasattr(db_local, \"conn\"):\n        db_local.conn = sqlite3.connect(DATABASE)",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "DATABASE",
        "kind": 5,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "DATABASE = \"inventory.db\"\ndb_local = threading.local()\ndef get_db():\n    \"\"\"Get database connection with row factory\"\"\"\n    if not hasattr(db_local, \"conn\"):\n        db_local.conn = sqlite3.connect(DATABASE)\n        db_local.conn.row_factory = sqlite3.Row\n    return db_local.conn\ndef close_db():\n    \"\"\"Close the database connection\"\"\"",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "db_local",
        "kind": 5,
        "importPath": "core.main",
        "description": "core.main",
        "peekOfCode": "db_local = threading.local()\ndef get_db():\n    \"\"\"Get database connection with row factory\"\"\"\n    if not hasattr(db_local, \"conn\"):\n        db_local.conn = sqlite3.connect(DATABASE)\n        db_local.conn.row_factory = sqlite3.Row\n    return db_local.conn\ndef close_db():\n    \"\"\"Close the database connection\"\"\"\n    if hasattr(db_local, \"conn\"):",
        "detail": "core.main",
        "documentation": {}
    },
    {
        "label": "TaskManager",
        "kind": 6,
        "importPath": "core.task_manager",
        "description": "core.task_manager",
        "peekOfCode": "class TaskManager:\n    def __init__(self, db_path='inventory.db'):\n        self.db_path = db_path\n        self.conn = sqlite3.connect(db_path)\n        self.create_tables()\n    def create_tables(self):\n        cursor = self.conn.cursor()\n        # Table for repair tasks\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS repairs (",
        "detail": "core.task_manager",
        "documentation": {}
    },
    {
        "label": "check_receipts",
        "kind": 2,
        "importPath": "scripts.check_receipts",
        "description": "scripts.check_receipts",
        "peekOfCode": "def check_receipts():\n    \"\"\"Check the contents of the purchases and purchase_items tables.\"\"\"\n    conn = sqlite3.connect(\"db/inventory.db\")\n    cursor = conn.cursor()\n    # Check if purchases table exists\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='purchases'\")\n    if cursor.fetchone() is None:\n        print(\"Purchases table does not exist.\")\n    else:\n        # Fetch purchases",
        "detail": "scripts.check_receipts",
        "documentation": {}
    },
    {
        "label": "generate_variants",
        "kind": 2,
        "importPath": "scripts.generate_training_data",
        "description": "scripts.generate_training_data",
        "peekOfCode": "def generate_variants(item, num_variants=10):  # Increased default number of variants\n    variants = []\n    for _ in range(num_variants):\n        variant = item.copy()\n        # Randomly modify the name and description\n        variant['name'] = variant['name'] + ' Variant ' + str(random.randint(1, 100))\n        variant['description'] = variant['description'] + ' - Modified'\n        # Additional random modifications\n        variant['price'] = round(random.uniform(1.0, 100.0), 2)  # Random price\n        variant['category'] = random.choice(['Electronics', 'Clothing', 'Food', 'Books'])  # Random category",
        "detail": "scripts.generate_training_data",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.generate_training_data",
        "description": "scripts.generate_training_data",
        "peekOfCode": "def main():\n    inventory_manager = InventoryManager(db_path='inventory.db')\n    items_given_away = inventory_manager.get_items_given_away()\n    all_variants = []\n    for item in items_given_away:\n        variants = generate_variants(item)\n        all_variants.extend(variants)\n    # Print or save the variants for training\n    for variant in all_variants:\n        print(variant)",
        "detail": "scripts.generate_training_data",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "scripts.init_db",
        "description": "scripts.init_db",
        "peekOfCode": "def init_db():\n    \"\"\"Initialize the database with required tables.\"\"\"\n    # Ensure the db directory exists\n    base_dir = os.path.dirname(os.path.dirname(__file__))\n    db_dir = os.path.join(base_dir, \"db\")\n    os.makedirs(db_dir, exist_ok=True)\n    db_path = os.path.join(db_dir, \"inventory.db\")\n    # Connect to the database (creates it if it doesn't exist)\n    conn = sqlite3.connect(db_path)\n    conn.row_factory = sqlite3.Row",
        "detail": "scripts.init_db",
        "documentation": {}
    },
    {
        "label": "init_db",
        "kind": 2,
        "importPath": "scripts.init_db_backup",
        "description": "scripts.init_db_backup",
        "peekOfCode": "def init_db():\n    \"\"\"Initialize the database with required tables.\"\"\"\n    # Ensure db directory exists\n    db_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), \"db\")\n    os.makedirs(db_dir, exist_ok=True)\n    db_path = os.path.join(db_dir, \"inventory.db\")\n    # Connect to database (creates it if it doesn't exist)\n    conn = sqlite3.connect(db_path)\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()",
        "detail": "scripts.init_db_backup",
        "documentation": {}
    },
    {
        "label": "install_dependencies",
        "kind": 2,
        "importPath": "scripts.install_deps",
        "description": "scripts.install_deps",
        "peekOfCode": "def install_dependencies():\n    \"\"\"Install or update project dependencies\"\"\"\n    try:\n        # Get the project root directory (where requirements.txt is located)\n        project_root = Path(__file__).parent.parent\n        requirements_file = project_root / \"requirements.txt\"\n        if not requirements_file.exists():\n            print(\"Error: requirements.txt not found!\")\n            return False\n        print(\"Uninstalling potentially conflicting packages...\")",
        "detail": "scripts.install_deps",
        "documentation": {}
    },
    {
        "label": "TestRunner",
        "kind": 6,
        "importPath": "scripts.run_tests",
        "description": "scripts.run_tests",
        "peekOfCode": "class TestRunner:\n    def __init__(self):\n        self.project_root = Path(__file__).parent.parent\n        self.test_dir = self.project_root / \"tests\"\n        self.start_time = None\n        self.end_time = None\n    def print_header(self, message):\n        \"\"\"Print a formatted header\"\"\"\n        print(\"\\n\" + \"=\" * 80)\n        print(f\" {message} \".center(80, \"=\"))",
        "detail": "scripts.run_tests",
        "documentation": {}
    },
    {
        "label": "write_lint_errors",
        "kind": 2,
        "importPath": "scripts.run_tests",
        "description": "scripts.run_tests",
        "peekOfCode": "def write_lint_errors(errors, output_file=\"lint_errors.json\"):\n    \"\"\"Write linting errors to a JSON file\"\"\"\n    try:\n        with open(output_file, \"w\") as f:\n            json.dump(errors, f, indent=2)\n        print(f\"Lint errors written to {output_file}\")\n    except Exception as e:\n        print(f\"Error writing lint errors: {e}\")\ndef main():\n    parser = argparse.ArgumentParser(description=\"Run project tests with various options\")",
        "detail": "scripts.run_tests",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.run_tests",
        "description": "scripts.run_tests",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Run project tests with various options\")\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\", \n                        help=\"Enable verbose output\")\n    parser.add_argument(\"-c\", \"--coverage\", action=\"store_true\",\n                        help=\"Run tests with coverage report\")\n    parser.add_argument(\"-f\", \"--test-file\", type=str,\n                        help=\"Run specific test file (e.g., test_nlu_processor.py)\")\n    parser.add_argument(\"-t\", \"--test-function\", type=str,\n                        help=\"Run specific test function (e.g., test_inventory_query)\")",
        "detail": "scripts.run_tests",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": "scripts.train_nlu",
        "description": "scripts.train_nlu",
        "peekOfCode": "def load_and_prepare_data(data_path=None, label_mapping=None):\n    \"\"\"Load training data from file or use default examples if no file provided.\"\"\"\n    if data_path and os.path.exists(data_path):\n        df = pd.read_csv(data_path)\n        df[\"label\"] = df[\"intent\"].map(label_mapping)\n        df = df.dropna(subset=[\"label\"])\n        return df[\"query\"].tolist(), df[\"label\"].tolist()\n    X = [\n        \"show me all items in the kitchen\",\n        \"how many items do I have in the garage\",",
        "detail": "scripts.train_nlu",
        "documentation": {}
    },
    {
        "label": "create_dataset",
        "kind": 2,
        "importPath": "scripts.train_nlu",
        "description": "scripts.train_nlu",
        "peekOfCode": "def create_dataset(queries, labels, tokenizer):\n    \"\"\"Create a Dataset object from queries and labels.\"\"\"\n    tokenized_inputs = tokenizer(\n        queries, padding=True, truncation=True, return_tensors=\"pt\"\n    )\n    return Dataset.from_dict(\n        {\n            \"input_ids\": tokenized_inputs[\"input_ids\"].tolist(),\n            \"attention_mask\": tokenized_inputs[\"attention_mask\"].tolist(),\n            \"labels\": [int(label) for label in labels],",
        "detail": "scripts.train_nlu",
        "documentation": {}
    },
    {
        "label": "mock_db_connection",
        "kind": 2,
        "importPath": "scripts.train_nlu",
        "description": "scripts.train_nlu",
        "peekOfCode": "def mock_db_connection():\n    \"\"\"Create an in-memory SQLite database with the 'items' table and sample data.\"\"\"\n    conn = sqlite3.connect(\":memory:\")\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    # Create the 'items' table\n    cursor.execute(\n        \"\"\"\n        CREATE TABLE items (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "scripts.train_nlu",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.train_nlu",
        "description": "scripts.train_nlu",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Train an enhanced NLU model.\")\n    parser.add_argument(\"--data\", type=str, help=\"Path to CSV training data (optional)\")\n    parser.add_argument(\n        \"--epochs\", type=int, default=3, help=\"Number of training epochs\"\n    )\n    parser.add_argument(\n        \"--batch_size\", type=int, default=16, help=\"Training batch size\"\n    )\n    parser.add_argument(",
        "detail": "scripts.train_nlu",
        "documentation": {}
    },
    {
        "label": "test_app",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def test_app():\n    \"\"\"Create a test Flask application\"\"\"\n    app.config['TESTING'] = True\n    return app\n@pytest.fixture\ndef client(test_app) -> FlaskClient:\n    \"\"\"Create a test client\"\"\"\n    return test_app.test_client()\n@pytest.fixture\ndef test_db():",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def client(test_app) -> FlaskClient:\n    \"\"\"Create a test client\"\"\"\n    return test_app.test_client()\n@pytest.fixture\ndef test_db():\n    \"\"\"Create a test database connection\"\"\"\n    # Use an in-memory database for testing\n    conn = sqlite3.connect(':memory:')\n    # Set up the row factory to return dictionaries\n    def dict_factory(cursor, row):",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "test_db",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def test_db():\n    \"\"\"Create a test database connection\"\"\"\n    # Use an in-memory database for testing\n    conn = sqlite3.connect(':memory:')\n    # Set up the row factory to return dictionaries\n    def dict_factory(cursor, row):\n        d = {}\n        for idx, col in enumerate(cursor.description):\n            d[col[0]] = row[idx]\n        return d",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "sample_data",
        "kind": 2,
        "importPath": "tests.conftest",
        "description": "tests.conftest",
        "peekOfCode": "def sample_data(test_db):\n    \"\"\"Insert sample data into the test database\"\"\"\n    cursor = test_db.cursor()\n    # Insert sample items with all necessary fields\n    cursor.execute(\"\"\"\n        INSERT INTO items (\n            name, description, quantity, price, location, category, \n            tags, purchase_date, is_gift, storage_location, usage_location, needs_repair,\n            warranty_expiry, acquisition_type, condition, notes\n        )",
        "detail": "tests.conftest",
        "documentation": {}
    },
    {
        "label": "init_test_db",
        "kind": 2,
        "importPath": "tests.init_test_db",
        "description": "tests.init_test_db",
        "peekOfCode": "def init_test_db(db_conn):\n    \"\"\"Initialize the test database with required tables.\"\"\"\n    cursor = db_conn.cursor()\n    # Create items table with additional fields\n    cursor.execute(\n        \"\"\"\n    CREATE TABLE IF NOT EXISTS items (\n        id INTEGER PRIMARY KEY AUTOINCREMENT,\n        name TEXT NOT NULL,\n        description TEXT,",
        "detail": "tests.init_test_db",
        "documentation": {}
    },
    {
        "label": "test_query_endpoint_items",
        "kind": 2,
        "importPath": "tests.test_api_endpoints",
        "description": "tests.test_api_endpoints",
        "peekOfCode": "def test_query_endpoint_items(client, sample_data):\n    \"\"\"Test the /api/query endpoint with an items query\"\"\"\n    response = client.post('/api/query', \n                         json={'query': 'Show me all items'})\n    assert response.status_code == 200\n    data = json.loads(response.data)\n    assert \"response\" in data\n    assert \"items in inventory\" in data[\"response\"]\ndef test_query_endpoint_repairs(client, sample_data):\n    \"\"\"Test the /api/query endpoint with a repairs query\"\"\"",
        "detail": "tests.test_api_endpoints",
        "documentation": {}
    },
    {
        "label": "test_query_endpoint_repairs",
        "kind": 2,
        "importPath": "tests.test_api_endpoints",
        "description": "tests.test_api_endpoints",
        "peekOfCode": "def test_query_endpoint_repairs(client, sample_data):\n    \"\"\"Test the /api/query endpoint with a repairs query\"\"\"\n    response = client.post('/api/query', \n                         json={'query': 'Show repair history'})\n    assert response.status_code == 200\n    data = json.loads(response.data)\n    assert \"response\" in data\n    assert \"repair records\" in data[\"response\"]\ndef test_query_endpoint_no_query(client):\n    \"\"\"Test the /api/query endpoint with missing query\"\"\"",
        "detail": "tests.test_api_endpoints",
        "documentation": {}
    },
    {
        "label": "test_query_endpoint_no_query",
        "kind": 2,
        "importPath": "tests.test_api_endpoints",
        "description": "tests.test_api_endpoints",
        "peekOfCode": "def test_query_endpoint_no_query(client):\n    \"\"\"Test the /api/query endpoint with missing query\"\"\"\n    response = client.post('/api/query', json={})\n    assert response.status_code == 400\n    data = json.loads(response.data)\n    assert \"error\" in data\ndef test_query_endpoint_empty_query(client):\n    \"\"\"Test the /api/query endpoint with empty query string\"\"\"\n    response = client.post('/api/query', \n                         json={'query': ''})",
        "detail": "tests.test_api_endpoints",
        "documentation": {}
    },
    {
        "label": "test_query_endpoint_empty_query",
        "kind": 2,
        "importPath": "tests.test_api_endpoints",
        "description": "tests.test_api_endpoints",
        "peekOfCode": "def test_query_endpoint_empty_query(client):\n    \"\"\"Test the /api/query endpoint with empty query string\"\"\"\n    response = client.post('/api/query', \n                         json={'query': ''})\n    assert response.status_code == 400\n    data = json.loads(response.data)\n    assert \"error\" in data",
        "detail": "tests.test_api_endpoints",
        "documentation": {}
    },
    {
        "label": "inventory_manager",
        "kind": 2,
        "importPath": "tests.test_inventory_manager",
        "description": "tests.test_inventory_manager",
        "peekOfCode": "def inventory_manager():\n    return InventoryManager(db_path=':memory:')\ndef test_gave_away(inventory_manager):\n    \"\"\"Test the gave_away method\"\"\"\n    item_id = inventory_manager.gave_away(\n        name=\"Old Book\",\n        description=\"A worn-out book\",\n        quantity=1,\n        notes=\"Donated to library\"\n    )",
        "detail": "tests.test_inventory_manager",
        "documentation": {}
    },
    {
        "label": "test_gave_away",
        "kind": 2,
        "importPath": "tests.test_inventory_manager",
        "description": "tests.test_inventory_manager",
        "peekOfCode": "def test_gave_away(inventory_manager):\n    \"\"\"Test the gave_away method\"\"\"\n    item_id = inventory_manager.gave_away(\n        name=\"Old Book\",\n        description=\"A worn-out book\",\n        quantity=1,\n        notes=\"Donated to library\"\n    )\n    assert item_id is not None\n    # Verify the item is logged in the items_given_away table",
        "detail": "tests.test_inventory_manager",
        "documentation": {}
    },
    {
        "label": "setup_database",
        "kind": 2,
        "importPath": "tests.test_nlu",
        "description": "tests.test_nlu",
        "peekOfCode": "def setup_database():\n    \"\"\"Set up an in-memory SQLite database with the 'items' table and sample data.\"\"\"\n    conn = sqlite3.connect(\":memory:\")  # In-memory database for testing\n    conn.row_factory = sqlite3.Row\n    cursor = conn.cursor()\n    # Create the 'items' table\n    cursor.execute(\n        \"\"\"\n        CREATE TABLE items (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,",
        "detail": "tests.test_nlu",
        "documentation": {}
    },
    {
        "label": "test_queries",
        "kind": 2,
        "importPath": "tests.test_nlu",
        "description": "tests.test_nlu",
        "peekOfCode": "def test_queries(test_db):\n    \"\"\"Run test queries against the NLUProcessor with the provided database connection.\"\"\"\n    nlu = NLUProcessor()\n    test_cases = [\n        \"show me all items in the kitchen\",  # Search by location\n        \"how many products do I have\",  # Count total items\n        \"what is the total value of my inventory\",  # Total value\n        \"list items that cost more than 100 dollars\",  # Price range (high)\n        \"count all things in storage\",  # Count by location\n        \"what items are in the living room\",  # Search by location",
        "detail": "tests.test_nlu",
        "documentation": {}
    },
    {
        "label": "test_intent_classification",
        "kind": 2,
        "importPath": "tests.test_nlu_processor",
        "description": "tests.test_nlu_processor",
        "peekOfCode": "def test_intent_classification():\n    \"\"\"Test the transformer model's intent classification\"\"\"\n    processor = NLUProcessor()\n    test_cases = [\n        (\"show me all items in the kitchen\", \"search\"),\n        (\"how many products do I have\", \"count\"),\n        (\"what is the total value of my inventory\", \"value\"),\n        (\"list items that cost more than 100 dollars\", \"price_range\"),\n        (\"unknown query that should fail\", \"unknown\")\n    ]",
        "detail": "tests.test_nlu_processor",
        "documentation": {}
    },
    {
        "label": "test_response_format",
        "kind": 2,
        "importPath": "tests.test_nlu_processor",
        "description": "tests.test_nlu_processor",
        "peekOfCode": "def test_response_format():\n    \"\"\"Test the response format for different intents\"\"\"\n    processor = NLUProcessor()\n    # Mock database cursor directly\n    class MockCursor:\n        def __init__(self):\n            self.query = \"\"\n            self.description = [(\"name\", None, None, None, None, None, None), \n                               (\"price\", None, None, None, None, None, None)]\n        def execute(self, query, params=None):",
        "detail": "tests.test_nlu_processor",
        "documentation": {}
    },
    {
        "label": "test_performance",
        "kind": 2,
        "importPath": "tests.test_nlu_processor",
        "description": "tests.test_nlu_processor",
        "peekOfCode": "def test_performance():\n    \"\"\"Test the performance of the NLU processor\"\"\"\n    processor = NLUProcessor()\n    # Mock cursor for testing\n    class MockCursor:\n        def __init__(self):\n            self.description = [(\"name\", None, None, None, None, None, None), \n                               (\"price\", None, None, None, None, None, None)]\n        def execute(self, query, params=None):\n            return self",
        "detail": "tests.test_nlu_processor",
        "documentation": {}
    },
    {
        "label": "test_error_handling",
        "kind": 2,
        "importPath": "tests.test_nlu_processor",
        "description": "tests.test_nlu_processor",
        "peekOfCode": "def test_error_handling():\n    \"\"\"Test error handling in the NLU processor\"\"\"\n    processor = NLUProcessor()\n    # Test database error\n    def failing_db():\n        raise Exception(\"Database connection failed\")\n    result = processor.process_natural_language_query(\"show me all items\", failing_db)\n    assert result.get(\"error\") == \"Database connection failed\"\n    # Mock cursor for testing\n    class MockCursor:",
        "detail": "tests.test_nlu_processor",
        "documentation": {}
    },
    {
        "label": "test_various_phrasings",
        "kind": 2,
        "importPath": "tests.test_nlu_processor",
        "description": "tests.test_nlu_processor",
        "peekOfCode": "def test_various_phrasings(query, expected_intent):\n    \"\"\"Test various phrasings for each intent\"\"\"\n    processor = NLUProcessor()\n    # Mock cursor for testing\n    class MockCursor:\n        def __init__(self):\n            self.description = [(\"name\", None, None, None, None, None, None), \n                               (\"price\", None, None, None, None, None, None)]\n        def execute(self, query, params=None):\n            return self",
        "detail": "tests.test_nlu_processor",
        "documentation": {}
    },
    {
        "label": "MockReceiptProcessor",
        "kind": 6,
        "importPath": "tests.test_ocr",
        "description": "tests.test_ocr",
        "peekOfCode": "class MockReceiptProcessor(ReceiptProcessor):\n    \"\"\"A modified version of ReceiptProcessor for testing purposes.\"\"\"\n    def preprocess_image(self, image_path_or_array):\n        \"\"\"Modified preprocessing for testing.\"\"\"\n        try:\n            # Handle both file paths and numpy arrays\n            if isinstance(image_path_or_array, str):\n                # Convert path to absolute path\n                abs_path = os.path.abspath(image_path_or_array)\n                print(f\"Loading image from path: {abs_path}\")",
        "detail": "tests.test_ocr",
        "documentation": {}
    },
    {
        "label": "TestOCRProcessor",
        "kind": 6,
        "importPath": "tests.test_ocr",
        "description": "tests.test_ocr",
        "peekOfCode": "class TestOCRProcessor(unittest.TestCase):\n    \"\"\"Test cases for OCR processor functionality.\"\"\"\n    def setUp(self):\n        \"\"\"Set up test environment.\"\"\"\n        # Use the mock processor for testing\n        self.processor = MockReceiptProcessor()\n        self.test_dir = tempfile.mkdtemp()\n    def tearDown(self):\n        \"\"\"Clean up test environment.\"\"\"\n        # Remove temporary files",
        "detail": "tests.test_ocr",
        "documentation": {}
    },
    {
        "label": "BudgetTracker",
        "kind": 6,
        "importPath": "utils.budget_tracker",
        "description": "utils.budget_tracker",
        "peekOfCode": "class BudgetTracker:\n    def __init__(self, db_path='inventory.db'):\n        self.db_path = db_path\n        self.conn = sqlite3.connect(db_path)\n        self.create_tables()\n    def create_tables(self):\n        cursor = self.conn.cursor()\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS budget (\n                id INTEGER PRIMARY KEY,",
        "detail": "utils.budget_tracker",
        "documentation": {}
    },
    {
        "label": "list_tables",
        "kind": 2,
        "importPath": "utils.inspect_db",
        "description": "utils.inspect_db",
        "peekOfCode": "def list_tables(db_path):\n    try:\n        conn = sqlite3.connect(db_path)\n        cursor = conn.cursor()\n        tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n        print(\"Tables in database:\")\n        for table in tables:\n            print(f\"- {table[0]}\")\n            # Print columns for each table\n            columns = cursor.execute(f\"PRAGMA table_info({table[0]})\").fetchall()",
        "detail": "utils.inspect_db",
        "documentation": {}
    },
    {
        "label": "populate_test_data",
        "kind": 2,
        "importPath": "utils.populate_test_data",
        "description": "utils.populate_test_data",
        "peekOfCode": "def populate_test_data(db_path):\n    conn = sqlite3.connect(db_path)\n    cursor = conn.cursor()\n    # Insert test items\n    cursor.executemany(\"\"\"\n        INSERT INTO items (name, description, quantity, purchase_date, price)\n        VALUES (?, ?, ?, ?, ?)\n    \"\"\", [\n        (\"Test Item 1\", \"First test item\", 5, \"2023-01-01\", 100.0),\n        (\"Test Item 2\", \"Second test item\", 3, \"2023-02-01\", 150.0)",
        "detail": "utils.populate_test_data",
        "documentation": {}
    },
    {
        "label": "start_application",
        "kind": 2,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "def start_application():\n    \"\"\"Start the Flask application\"\"\"\n    print(\"Starting Todoist application...\")\n    # Set Python path before running the application\n    env = os.environ.copy()\n    env[\"PYTHONPATH\"] = os.path.abspath(os.path.dirname(__file__))\n    subprocess.run([\"python\", \"core/main.py\"], env=env)\ndef train_model(epochs=3, batch_size=16, model_dir=\"ai_models\"):\n    \"\"\"Train the NLU model\"\"\"\n    print(\"Training NLU model...\")",
        "detail": "start",
        "documentation": {}
    },
    {
        "label": "train_model",
        "kind": 2,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "def train_model(epochs=3, batch_size=16, model_dir=\"ai_models\"):\n    \"\"\"Train the NLU model\"\"\"\n    print(\"Training NLU model...\")\n    subprocess.run([\"python\", \"scripts/train_nlu.py\", \"--epochs\", str(epochs), \"--batch_size\", str(batch_size), \"--model_dir\", model_dir])\ndef run_tests():\n    \"\"\"Run all tests\"\"\"\n    print(\"Running tests...\")\n    subprocess.run([\"pytest\", \"tests/\"])\ndef add_data():\n    \"\"\"Add sample data to the database\"\"\"",
        "detail": "start",
        "documentation": {}
    },
    {
        "label": "run_tests",
        "kind": 2,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "def run_tests():\n    \"\"\"Run all tests\"\"\"\n    print(\"Running tests...\")\n    subprocess.run([\"pytest\", \"tests/\"])\ndef add_data():\n    \"\"\"Add sample data to the database\"\"\"\n    print(\"Adding sample data...\")\n    subprocess.run([\"python\", \"utils/populate_test_data.py\"])\ndef main():\n    parser = argparse.ArgumentParser(description=\"Todoist Application Management\")",
        "detail": "start",
        "documentation": {}
    },
    {
        "label": "add_data",
        "kind": 2,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "def add_data():\n    \"\"\"Add sample data to the database\"\"\"\n    print(\"Adding sample data...\")\n    subprocess.run([\"python\", \"utils/populate_test_data.py\"])\ndef main():\n    parser = argparse.ArgumentParser(description=\"Todoist Application Management\")\n    parser.add_argument(\"command\", choices=[\"start\", \"train\", \"test\", \"add-data\"],\n                       help=\"Command to execute: start, train, test, or add-data\")\n    args = parser.parse_args()\n    if args.command == \"start\":",
        "detail": "start",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Todoist Application Management\")\n    parser.add_argument(\"command\", choices=[\"start\", \"train\", \"test\", \"add-data\"],\n                       help=\"Command to execute: start, train, test, or add-data\")\n    args = parser.parse_args()\n    if args.command == \"start\":\n        start_application()\n    elif args.command == \"train\":\n        train_model()\n    elif args.command == \"test\":",
        "detail": "start",
        "documentation": {}
    },
    {
        "label": "root_dir",
        "kind": 5,
        "importPath": "start",
        "description": "start",
        "peekOfCode": "root_dir = os.path.abspath(os.path.dirname(__file__))\nsys.path.insert(0, root_dir)\nimport subprocess\nimport sys\nimport os\ndef start_application():\n    \"\"\"Start the Flask application\"\"\"\n    print(\"Starting Todoist application...\")\n    # Set Python path before running the application\n    env = os.environ.copy()",
        "detail": "start",
        "documentation": {}
    }
]